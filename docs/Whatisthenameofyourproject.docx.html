<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=fpjTOVmNbO4Lz34iLyptLcWpXo_CmM6erK5IinBZ-8N8u45WU12y72TEk3aAZtZE');.lst-kix_qg00rkiapvya-8>li:before{content:"\0025a0  "}.lst-kix_qg00rkiapvya-5>li:before{content:"\0025a0  "}.lst-kix_qg00rkiapvya-7>li:before{content:"\0025cb  "}.lst-kix_qg00rkiapvya-6>li:before{content:"\0025cf  "}.lst-kix_qg00rkiapvya-2>li:before{content:"\0025a0  "}ul.lst-kix_qg00rkiapvya-7{list-style-type:none}ul.lst-kix_qg00rkiapvya-6{list-style-type:none}.lst-kix_qg00rkiapvya-1>li:before{content:"\0025cb  "}.lst-kix_qg00rkiapvya-3>li:before{content:"\0025cf  "}ul.lst-kix_qg00rkiapvya-5{list-style-type:none}ul.lst-kix_qg00rkiapvya-4{list-style-type:none}.lst-kix_qg00rkiapvya-0>li:before{content:"\0025cf  "}.lst-kix_qg00rkiapvya-4>li:before{content:"\0025cb  "}ul.lst-kix_qg00rkiapvya-8{list-style-type:none}ul.lst-kix_qg00rkiapvya-3{list-style-type:none}ul.lst-kix_qg00rkiapvya-2{list-style-type:none}ul.lst-kix_qg00rkiapvya-1{list-style-type:none}ul.lst-kix_qg00rkiapvya-0{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c4{background-color:#ffffff;color:#202124;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Roboto";font-style:normal}.c7{background-color:#ffffff;color:#032f62;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c8{background-color:#ffffff;color:#2e75b5;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Calibri";font-style:normal}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Calibri";font-style:normal}.c15{color:#202124;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.5pt;font-family:"Arial";font-style:normal}.c16{padding-top:12pt;padding-bottom:0pt;line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c18{color:#2e75b5;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Calibri";font-style:normal}.c12{color:#d93025;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Roboto";font-style:normal}.c13{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Calibri";font-style:normal}.c1{padding-top:0pt;padding-bottom:8pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:left}.c0{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c10{background-color:#fdf5d4;font-size:10pt;font-family:"Courier New";font-weight:400}.c2{background-color:#ffffff;max-width:451.3pt;padding:72pt 72pt 72pt 72pt}.c6{color:inherit;text-decoration:inherit}.c17{padding:0;margin:0}.c14{margin-left:36pt;padding-left:0pt}.c3{height:11pt}.c11{background-color:#ffffff}.c9{font-weight:700}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.0791666666666666;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Calibri"}p{margin:0;color:#000000;font-size:11pt;font-family:"Calibri"}h1{padding-top:12pt;color:#2e75b5;font-size:16pt;padding-bottom:0pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Calibri";line-height:1.0791666666666666;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c2"><h1 class="c16"><span class="c8">What is the name of your project?&nbsp;</span></h1><p class="c1"><span class="c5 c11">Making energy efficiency fun through targeted dashboards.</span></p><h1 class="c16"><span class="c8">What category are you submitting this project to? (Examples of write-in categories might be Fashion, Animals, etc)&nbsp;</span></h1><p class="c1"><span class="c4">Environment - Building energy efficiency. </span></p><h1 class="c16"><span class="c11">We want to hear your project&#39;s story! Explain how the idea for this project was conceived, the motivation behind it, and how your project was executed.&nbsp;</span><span class="c12 c11">*</span></h1><p class="c1"><span class="c5">Information about the building coming sensors can be displayed in an unlimited number of forms through public dashboards. However, this information can be confusing for building users of certain ages, especially when the users are kids. No building user is irrelevant, thus we aim to include them in the energy efficiency journey through special dashboards that provide information targeted for children but at the same time, detailed information is available when adults are looking at them.</span></p><p class="c1"><span class="c13 c9">Typical advanced dashboard:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 302.42px; height: 388.50px;"><img alt="" src="images/image9.png" style="width: 302.42px; height: 388.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.73px; height: 186.87px;"><img alt="" src="images/image7.png" style="width: 601.73px; height: 186.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c9">Kids-friendly dashboard, more in (</span><span class="c0 c9"><a class="c6" href="https://www.google.com/url?q=http://bit.ly/2XwZX20&amp;sa=D&amp;ust=1582380136202000">http://bit.ly/2XwZX20</a></span><span class="c9 c13">):</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.73px; height: 343.40px;"><img alt="" src="images/image10.png" style="width: 601.73px; height: 343.40px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.73px; height: 342.33px;"><img alt="" src="images/image5.png" style="width: 601.73px; height: 342.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.73px; height: 342.93px;"><img alt="" src="images/image1.png" style="width: 601.73px; height: 342.93px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c5">To achieve this, we assume that a camera will be installed on top of a monitor that displays dashboards. Then, we deployed a script that uses three deep learning models that (1) detects faces on a video stream coming from the camera, (2) estimates the age of the detected faces, (3) if any of the detected faces is older than 21 y/o, then a head pose estimation model determines whether the person is looking at the dashboard. When it is detected that a adult person is looking toward the screen, the dashboard will be switched from a children friendly &nbsp;to a more advanced dashboard that contains technical information. If an adult is no longer looking at the dashboard, it will change eventually to the kids&rsquo; version again. </span></p><p class="c1"><span>The project set-up assumes the existence of two hypothetical dashboard projects that are clearly for two different user groups (e.g. facility managers and children of the same school). Software required was, VNC viewer, Python 3.7, </span><span><a class="c6" href="https://www.google.com/url?q=https://mqtt.org/tag/mosquitto&amp;sa=D&amp;ust=1582380136203000">&nbsp;</a></span><span class="c0"><a class="c6" href="https://www.google.com/url?q=https://mqtt.org/tag/mosquitto&amp;sa=D&amp;ust=1582380136203000">mosquitto</a></span><span>,</span><span><a class="c6" href="https://www.google.com/url?q=https://docs.openvinotoolkit.org/latest/_docs_install_guides_installing_openvino_raspbian.html&amp;sa=D&amp;ust=1582380136204000">&nbsp;</a></span><span class="c0"><a class="c6" href="https://www.google.com/url?q=https://docs.openvinotoolkit.org/latest/_docs_install_guides_installing_openvino_raspbian.html&amp;sa=D&amp;ust=1582380136204000">OpenVINO</a></span><span class="c5">, and its dependencies, such as OpenCV and CMake. Hardware used for this project consist on a Neural Compute Stick II, a &nbsp;Raspberry Pi 4, a High Definition webcam. The Neural Compute Stick II provides the extra processing power required to execute deep learning applications in small devices.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 335.00px; height: 201.00px;"><img alt="" src="images/image6.jpg" style="width: 335.00px; height: 252.00px; margin-left: 0.00px; margin-top: -33.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 244.74px; height: 201.50px;"><img alt="" src="images/image4.jpg" style="width: 267.62px; height: 201.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c5">Pre trained models used were:</span></p><ul class="c17 lst-kix_qg00rkiapvya-0 start"><li class="c1 c14"><span class="c0"><a class="c6" href="https://www.google.com/url?q=https://docs.openvinotoolkit.org/2019_R1/_face_detection_retail_0004_description_face_detection_retail_0004.html&amp;sa=D&amp;ust=1582380136205000">face-detection-retail-0004</a></span></li><li class="c1 c14"><span class="c0"><a class="c6" href="https://www.google.com/url?q=https://docs.openvinotoolkit.org/2019_R1/_head_pose_estimation_adas_0001_description_head_pose_estimation_adas_0001.html&amp;sa=D&amp;ust=1582380136205000">head-pose-estimation-adas-0001</a></span></li><li class="c1 c14"><span class="c0"><a class="c6" href="https://www.google.com/url?q=https://docs.openvinotoolkit.org/2019_R1/_age_gender_recognition_retail_0013_description_age_gender_recognition_retail_0013.html&amp;sa=D&amp;ust=1582380136206000">age-gender-recognition-retail-0013</a></span></li></ul><p class="c1"><span>The script is intended to take video information from a default camera. In order to use 3 model at once, we need to have 3 inference engines: one for face detection (the first on the list to be executed), one for age gender and one for head pose. First, we detect faces that have a threshold higher than 0.5 and put them in a list. For each of the detected faces, the script extracts the age and head pose. To determine whether a person is looking to the screen, an angle range is required both from yaw and pitch. In this case, it was determined that if the head pose is within a range is &gt;-30 and &lt;30, then the person is &ldquo;looking&rdquo;. Finally, if a person is both &ldquo;looking&rdquo; and has an age over 21, then a new topic &ldquo;adult&rdquo; is sent. For all the other conditions, the topic &ldquo;kids&rdquo; is sent through MQTT client. &nbsp;</span><span class="c5">It is worth mentioning that no video is ever taken away from the Raspberry Pi, all is processed locally, the age and head position is determined and then the picture/video is deleted.</span></p><p class="c1"><span>In future work, the MQTT message will be incorporate to a new script that can swap across dashboards (kids and adults)</span><span class="c0"><a class="c6" href="https://www.google.com/url?q=https://pimylifeup.com/raspberry-pi-kiosk/&amp;sa=D&amp;ust=1582380136207000">&nbsp;following these instructions.</a></span></p><p class="c1 c3"><span class="c4"></span></p><h1 class="c16"><span class="c11">Please include a link to your README file here detailing a.) How to run the project and b). What are the various command line parameters which could be changed and how to change them.&nbsp;</span><span class="c11 c12">*</span></h1><p class="c1"><span class="c5">Github link (readme file included):</span></p><p class="c1"><span class="c0"><a class="c6" href="https://www.google.com/url?q=https://github.com/nesreensada/Targeted-Dashboards-with-OpenVINO&amp;sa=D&amp;ust=1582380136207000">https://github.com/nesreensada/Targeted-Dashboards-with-OpenVINO</a></span></p><p class="c1 c3"><span class="c5"></span></p><p class="c1"><span class="c5">The dashboard_app.py contains the starting point of the project, this code needs to be executed with the required arguments that are parses using the arg parser. Arguments include the path to the pre trained models (face detection,age &nbsp;gender model and head pose). </span></p><p class="c1"><span>To execute the project, first ensure that you have installed all the required dependencies for Raspberry Pi 4 and Neural Compute Stick II by following instructions from </span><span class="c0"><a class="c6" href="https://www.google.com/url?q=https://docs.openvinotoolkit.org/latest/_docs_install_guides_installing_openvino_raspbian.html&amp;sa=D&amp;ust=1582380136208000">this post</a></span><span>, then open a command window and type</span><span class="c5">:</span></p><p class="c1"><span class="c10">python3.7 dashboard_app.py -fm models/face-detection-retail-0004/FP16/face-detection-retail-0004.xml -pm models/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml -ag_m models/age-gender-recognition-retail-0013/FP16/age-gender-recognition-retail-0013.xml -d </span><span class="c10">MYRIAD</span></p><p class="c1 c3"><span class="c7"></span></p><p class="c1"><span>&nbsp;To open MQTT local port, first ensure that all dependencies are installed, &nbsp;follow instructions </span><span class="c0"><a class="c6" href="https://www.google.com/url?q=https://appcodelabs.com/introduction-to-iot-build-an-mqtt-server-using-raspberry-pi&amp;sa=D&amp;ust=1582380136209000">in this post</a></span><span>, then open a new command window and type:</span></p><p class="c1"><span class="c10">mosquitto_sub -h localhost -t &quot;test/message&quot;</span></p><p class="c1 c3"><span class="c7"></span></p><h1 class="c16"><span class="c18">What goal are you hoping to achieve with your project?</span></h1><p class="c1"><span class="c5">Ensure that all building users, no matter their age, are well informed and aware of the importance of their role in the energy efficiency journey through the use of targeted dashboards.</span></p><h1 class="c16"><span class="c11">How did the Intel&reg; Edge AI Fundamentals Course help you in creating your project?&nbsp;</span><span class="c12 c11">*</span></h1><p class="c1" id="h.gjdgxs"><span class="c5">Through the Intel&reg; Edge AI Fundamentals Course we gained the knowledge to deploy multiple deep learning models in the edge applied to practical situation. Also, the introduction of MQTT concepts were key for the project. Finally, we learnt about the existence of the Neural Compute Stick II, which we have acquired and it was key on the development of the project. </span></p><h1 class="c16"><span class="c8">Please provide either screenshots of your project&#39;s result / expected outcome or a link to a demo video below (optional)</span></h1><p class="c1"><span>We have created a 2-minute demo video, using the following set up. </span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 452.00px;"><img alt="" src="images/image8.jpg" style="width: 602.00px; height: 452.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span>The output of the &nbsp;dasboard_app.py looks like this:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 352.00px;"><img alt="" src="images/image2.png" style="width: 602.00px; height: 352.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c3"><span class="c7"></span></p><p class="c1"><span class="c5">The MQTT client window output &nbsp;looks like this:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 602.00px; height: 388.00px;"><img alt="" src="images/image3.png" style="width: 602.00px; height: 388.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h1 class="c16"><span class="c8">A link to your demo video or website so we can see your project in action (optional)</span></h1><p class="c1"><span>We have done a quick demo, a URL to a video located in a google drive location is also provided.</span></p><p class="c1"><span class="c5">Link to the video:</span></p><p class="c1"><span class="c0"><a class="c6" href="https://www.google.com/url?q=https://drive.google.com/open?id%3D1PRkzS84PQ8UVqfDYgA4mxMUZKRK4xdfa&amp;sa=D&amp;ust=1582380136212000">https://drive.google.com/open?id=1PRkzS84PQ8UVqfDYgA4mxMUZKRK4xdfa</a></span></p><p class="c1 c3"><span class="c5"></span></p><p class="c1 c3"><span class="c7"></span></p><p class="c1 c3"><span class="c7"></span></p><p class="c1 c3"><span class="c7"></span></p><p class="c1 c3"><span class="c7"></span></p></body></html>